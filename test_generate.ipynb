{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/scratch/d/daniel.levy/MatSci/intel-mat-diffusion/diffcsp/pl_data/dataset.py:161: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n",
      "/network/scratch/d/daniel.levy/MatSci/intel-mat-diffusion/diffcsp/pl_data/datamodule.py:143: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from torch_geometric.data import Data, Batch, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from scripts.eval_utils import load_model, lattices_to_params_shape, get_crystals_list\n",
    "from diffcsp.common.constants import CompScalerMeans\n",
    "from diffcsp.common.constants import SpaceGroupDist\n",
    "\n",
    "from pymatgen.core.sites import PeriodicSite\n",
    "from pymatgen.core import Structure, Lattice\n",
    "\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from pymatgen.symmetry.groups import SpaceGroup, sg_symbol_from_int_number\n",
    "from pymatgen.io.cif import CifWriter\n",
    "from pyxtal.symmetry import Group\n",
    "import chemparse\n",
    "import numpy as np\n",
    "from p_tqdm import p_map\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "import nglview\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pdb\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset to sample from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist = {\n",
    "    'perov' : [0, 0, 0, 0, 0, 1],\n",
    "    'carbon' : [0.0,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                0.0,\n",
    "                0.3250697750779839,\n",
    "                0.0,\n",
    "                0.27795107535708424,\n",
    "                0.0,\n",
    "                0.15383352487276308,\n",
    "                0.0,\n",
    "                0.11246100804465604,\n",
    "                0.0,\n",
    "                0.04958134953209654,\n",
    "                0.0,\n",
    "                0.038745690362830404,\n",
    "                0.0,\n",
    "                0.019044491873255624,\n",
    "                0.0,\n",
    "                0.010178952552946971,\n",
    "                0.0,\n",
    "                0.007059596125430964,\n",
    "                0.0,\n",
    "                0.006074536200952225],\n",
    "    'mp' : [0.0,\n",
    "            0.0021742334905660377,\n",
    "            0.021079009433962265,\n",
    "            0.019826061320754717,\n",
    "            0.15271226415094338,\n",
    "            0.047132959905660375,\n",
    "            0.08464770047169812,\n",
    "            0.021079009433962265,\n",
    "            0.07808814858490566,\n",
    "            0.03434551886792453,\n",
    "            0.0972877358490566,\n",
    "            0.013303360849056603,\n",
    "            0.09669811320754718,\n",
    "            0.02155807783018868,\n",
    "            0.06522700471698113,\n",
    "            0.014372051886792452,\n",
    "            0.06703272405660378,\n",
    "            0.00972877358490566,\n",
    "            0.053176591981132074,\n",
    "            0.010576356132075472,\n",
    "            0.08995430424528301]\n",
    "}\n",
    "\n",
    "class SampleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, total_num):\n",
    "        super().__init__()\n",
    "        self.total_num = total_num\n",
    "        self.distribution = train_dist[dataset]\n",
    "        self.sg_distribution = SpaceGroupDist[dataset]\n",
    "\n",
    "        self.num_atoms = np.random.choice(len(self.distribution), total_num, p = self.distribution)\n",
    "        self.sg = np.random.choice(len(self.sg_distribution), total_num, p = self.sg_distribution)\n",
    "        self.is_carbon = dataset == 'carbon'\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.total_num\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        num_atom = self.num_atoms[index]\n",
    "        data = Data(\n",
    "            num_atoms=torch.LongTensor([num_atom]),\n",
    "            num_nodes=num_atom,\n",
    "            spacegroup=torch.LongTensor([self.sg[index]]),\n",
    "        )\n",
    "        if self.is_carbon:\n",
    "            data.atom_types = torch.LongTensor([6] * num_atom)\n",
    "        return data\n",
    "\n",
    "def get_num_atoms_per_sg(dataset):\n",
    "    if dataset == 'perov':\n",
    "        dataset_name = 'perov_4'\n",
    "    elif dataset == 'carbon':\n",
    "        dataset_name = 'carbon_24'\n",
    "    elif dataset == 'mp':\n",
    "        dataset_name = 'mp_20'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    dist_file = f'./data/{dataset_name}/num_atoms_per_sg.csv'\n",
    "    num_atoms_per_sg = np.loadtxt(dist_file, delimiter=',')\n",
    "    return num_atoms_per_sg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1\n",
    "num_batches_to_sample = 10\n",
    "test_set = SampleDataset(\"mp\", batch_size * num_batches_to_sample, True)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077f29d9cdfd4a48b41467841485eb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot3d(structure, spacefill=True, show_axes=True):\n",
    "    eps = 1e-8\n",
    "    sites = []\n",
    "    for site in structure:\n",
    "        species = site.species\n",
    "        frac_coords = np.remainder(site.frac_coords, 1)\n",
    "        for jimage in product([0, 1 - eps], repeat=3):\n",
    "            new_frac_coords = frac_coords + np.array(jimage)\n",
    "            if np.all(new_frac_coords < 1 + eps):\n",
    "                new_site = PeriodicSite(species=species, coords=new_frac_coords, lattice=structure.lattice)\n",
    "                sites.append(new_site)\n",
    "    structure_display = Structure.from_sites(sites)\n",
    "    \n",
    "    view = nglview.show_pymatgen(structure_display)\n",
    "    view.add_unitcell()\n",
    "    \n",
    "    if spacefill:\n",
    "        view.add_spacefill(radius_type='vdw', radius=0.5, color_scheme='element')\n",
    "        view.remove_ball_and_stick()\n",
    "    else:\n",
    "        view.add_ball_and_stick()\n",
    "        \n",
    "    if show_axes:\n",
    "        view.shape.add_arrow([-4, -4, -4], [0, -4, -4], [1, 0, 0], 0.5, \"x-axis\")\n",
    "        view.shape.add_arrow([-4, -4, -4], [-4, 0, -4], [0, 1, 0], 0.5, \"y-axis\")\n",
    "        view.shape.add_arrow([-4, -4, -4], [-4, -4, 0], [0, 0, 1], 0.5, \"z-axis\")\n",
    "        \n",
    "    view.camera = \"perspective\"\n",
    "    return view\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/network/scratch/d/daniel.levy/MatSci/intel-mat-diffusion/scripts/eval_utils.py:74: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize_config_dir(str(model_path)):\n",
      "/home/mila/d/daniel.levy/envs/matsciml/lib/python3.9/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n"
     ]
    }
   ],
   "source": [
    "model_path = Path(\"/home/mila/d/daniel.levy/scratch/MatSci/intel-mat-diffusion/hydra/singlerun/2023-12-22/mp_ks_cond_sg/\")\n",
    "model, _, cfg = load_model(\n",
    "    model_path, load_data=False)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffcsp.common.data_utils import (\n",
    "    EPSILON, cart_to_frac_coords, mard, lengths_angles_to_volume, lattice_params_to_matrix_torch,\n",
    "    frac_to_cart_coords, min_distance_sqr_pbc, lattice_ks_to_matrix_torch, sg_to_ks_mask, mask_ks, N_SPACEGROUPS)\n",
    "MAX_ATOMIC_NUM=100\n",
    "\n",
    "\n",
    "\n",
    "def sample(self, batch, diff_ratio = 1.0, step_lr = 1e-5):\n",
    "\n",
    "    batch_size = batch.num_graphs\n",
    "    if self.use_spacegroup and self.use_ks:\n",
    "            ks_mask, ks_add = sg_to_ks_mask(batch.spacegroup)\n",
    "\n",
    "    if self.use_ks:\n",
    "        k_T = torch.randn([batch_size, 6]).to(self.device)\n",
    "        if self.use_spacegroup:\n",
    "            k_T = mask_ks(k_T, ks_mask, ks_add)\n",
    "        l_T = lattice_ks_to_matrix_torch(k_T)\n",
    "    else:\n",
    "        l_T = torch.randn([batch_size, 3, 3]).to(self.device)\n",
    "        k_T = torch.zeros([batch_size, 6]).to(self.device) # dummy \n",
    "    x_T = torch.rand([batch.num_nodes, 3]).to(self.device)\n",
    "    t_T = torch.randn([batch.num_nodes, MAX_ATOMIC_NUM]).to(self.device)\n",
    "\n",
    "\n",
    "    if self.keep_coords:\n",
    "        x_T = batch.frac_coords\n",
    "\n",
    "    if self.keep_lattice:\n",
    "        k_T = batch.ks\n",
    "        l_T = lattice_params_to_matrix_torch(batch.lengths, batch.angles)     \n",
    "\n",
    "    traj = {self.beta_scheduler.timesteps : {\n",
    "        'num_atoms' : batch.num_atoms,\n",
    "        'atom_types' : t_T,\n",
    "        'frac_coords' : x_T % 1.,\n",
    "        'lattices' : l_T,\n",
    "        'ks': k_T\n",
    "    }}\n",
    "\n",
    "    for t in tqdm(range(self.beta_scheduler.timesteps, 0, -1)):\n",
    "\n",
    "        times = torch.full((batch_size, ), t, device = self.device)\n",
    "\n",
    "        time_emb = self.time_embedding(times)\n",
    "        \n",
    "        alphas = self.beta_scheduler.alphas[t]\n",
    "        alphas_cumprod = self.beta_scheduler.alphas_cumprod[t]\n",
    "\n",
    "        sigmas = self.beta_scheduler.sigmas[t]\n",
    "        sigma_x = self.sigma_scheduler.sigmas[t]\n",
    "        sigma_norm = self.sigma_scheduler.sigmas_norm[t]\n",
    "\n",
    "        c0 = 1.0 / torch.sqrt(alphas)\n",
    "        c1 = (1 - alphas) / torch.sqrt(1 - alphas_cumprod)\n",
    "\n",
    "        x_t = traj[t]['frac_coords']\n",
    "        l_t = traj[t]['lattices']\n",
    "        k_t = traj[t]['ks']\n",
    "        t_t = traj[t]['atom_types']\n",
    "\n",
    "        if self.keep_coords:\n",
    "            x_t = x_T\n",
    "\n",
    "        if self.keep_lattice:\n",
    "            k_t = k_T\n",
    "            l_t = l_T\n",
    "\n",
    "        # Corrector\n",
    "        # For whatever reason, lattice parameters are not updated in the original code.\n",
    "        if self.use_ks:\n",
    "            rand_k = torch.randn_like(k_T) if t > 1 else torch.zeros_like(k_T)\n",
    "        else:\n",
    "            rand_l = torch.randn_like(l_T) if t > 1 else torch.zeros_like(l_T)\n",
    "        rand_t = torch.randn_like(t_T) if t > 1 else torch.zeros_like(t_T)\n",
    "        rand_x = torch.randn_like(x_T) if t > 1 else torch.zeros_like(x_T)\n",
    "\n",
    "        step_size = step_lr * (sigma_x / self.sigma_scheduler.sigma_begin) ** 2\n",
    "        std_x = torch.sqrt(2 * step_size)\n",
    "\n",
    "        lattice_feats_t = k_t if self.use_ks else l_t\n",
    "        pred_lattice, pred_x, pred_t = self.decoder(time_emb, t_t, x_t, lattice_feats_t, l_t, batch.num_atoms, batch.batch, batch.spacegroup)\n",
    "\n",
    "        pred_x = pred_x * torch.sqrt(sigma_norm)\n",
    "\n",
    "        x_t_minus_05 = x_t - step_size * pred_x + std_x * rand_x if not self.keep_coords else x_t\n",
    "        k_t_minus_05 = k_t\n",
    "        l_t_minus_05 = l_t\n",
    "\n",
    "        t_t_minus_05 = t_t\n",
    "\n",
    "\n",
    "        # Predictor\n",
    "        if self.use_ks:\n",
    "            rand_k = torch.randn_like(k_T) if t > 1 else torch.zeros_like(k_T)\n",
    "        else:\n",
    "            rand_l = torch.randn_like(l_T) if t > 1 else torch.zeros_like(l_T)\n",
    "        rand_t = torch.randn_like(t_T) if t > 1 else torch.zeros_like(t_T)\n",
    "        rand_x = torch.randn_like(x_T) if t > 1 else torch.zeros_like(x_T)\n",
    "\n",
    "        adjacent_sigma_x = self.sigma_scheduler.sigmas[t-1] \n",
    "        step_size = (sigma_x ** 2 - adjacent_sigma_x ** 2)\n",
    "        std_x = torch.sqrt((adjacent_sigma_x ** 2 * (sigma_x ** 2 - adjacent_sigma_x ** 2)) / (sigma_x ** 2))   \n",
    "        lattice_feats_t_minus_05 = k_t_minus_05 if self.use_ks else l_t_minus_05\n",
    "\n",
    "        pred_lattice, pred_x, pred_t = self.decoder(time_emb, t_t_minus_05, x_t_minus_05, lattice_feats_t_minus_05, l_t_minus_05, batch.num_atoms, batch.batch, batch.spacegroup)\n",
    "\n",
    "        pred_x = pred_x * torch.sqrt(sigma_norm)\n",
    "\n",
    "        x_t_minus_1 = x_t_minus_05 - step_size * pred_x + std_x * rand_x if not self.keep_coords else x_t\n",
    "        if self.use_ks:\n",
    "            k_t_minus_1 = c0 * (k_t_minus_05 - c1 * pred_lattice) + sigmas * rand_k if not self.keep_lattice else k_t\n",
    "            if self.use_spacegroup and not self.keep_lattice:\n",
    "                k_t_minus_1 = mask_ks(k_t_minus_1, ks_mask, ks_add)\n",
    "            l_t_minus_1 = lattice_ks_to_matrix_torch(k_t_minus_1) if not self.keep_lattice else l_t\n",
    "        else:\n",
    "            l_t_minus_1 = c0 * (l_t_minus_05 - c1 * pred_lattice) + sigmas * rand_l if not self.keep_lattice else l_t\n",
    "            k_t_minus_1 = k_t\n",
    "\n",
    "        t_t_minus_1 = c0 * (t_t_minus_05 - c1 * pred_t) + sigmas * rand_t\n",
    "\n",
    "        traj[t - 1] = {\n",
    "            'num_atoms' : batch.num_atoms,\n",
    "            'atom_types' : t_t_minus_1,\n",
    "            'frac_coords' : x_t_minus_1 % 1.,\n",
    "            'lattices' : l_t_minus_1,\n",
    "            'ks': k_t_minus_1,\n",
    "        }\n",
    "        if self.use_spacegroup:\n",
    "            traj[t - 1]['spacegroup'] = batch.spacegroup\n",
    "\n",
    "    traj_stack = {\n",
    "        'num_atoms' : batch.num_atoms,\n",
    "        'atom_types' : torch.stack([traj[i]['atom_types'] for i in range(self.beta_scheduler.timesteps, -1, -1)]).argmax(dim=-1) + 1,\n",
    "        'all_frac_coords' : torch.stack([traj[i]['frac_coords'] for i in range(self.beta_scheduler.timesteps, -1, -1)]),\n",
    "        'all_lattices' : torch.stack([traj[i]['lattices'] for i in range(self.beta_scheduler.timesteps, -1, -1)]),\n",
    "        'all_ks': torch.stack([traj[i]['ks'] for i in range(self.beta_scheduler.timesteps, -1, -1)])\n",
    "    }\n",
    "\n",
    "    return traj[0], traj_stack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample crystal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5], device='cuda:0')\n",
      "tensor([164], device='cuda:0')\n",
      "DataBatch(num_atoms=[1], num_nodes=5, spacegroup=[1], batch=[5], ptr=[2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 80.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iter_test_loader = iter(test_loader)\n",
    "batch = next(iter_test_loader)\n",
    "batch.to('cuda')\n",
    "print(\"Num atoms: \", batch.num_atoms.item())\n",
    "print(\"Spacegroup: \", batch.spacegroup.item())\n",
    "outputs, traj = sample(model, batch, 1.0, 1e-5)\n",
    "def outputs_to_structure(output, batch_i=0):\n",
    "    lattice = output['lattices'][batch_i].detach().cpu().numpy()\n",
    "    atom_types = output['atom_types'].detach().cpu().numpy().argmax(1)+1\n",
    "    frac_coords = output['frac_coords'].detach().cpu().numpy()\n",
    "    return Structure(lattice, atom_types, frac_coords)\n",
    "\n",
    "structure = outputs_to_structure(outputs)\n",
    "spacegroup = outputs['spacegroup'].item()\n",
    "print(structure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at resulting crystal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real sg:  164\n",
      "target sg:  164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e484bc343c4655a3b1381dd15af6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "spga = SpacegroupAnalyzer(structure, symprec=0.1)\n",
    "real_sg = spga.get_space_group_number()\n",
    "print(\"real sg: \", real_sg)\n",
    "print(\"target sg: \", spacegroup)\n",
    "plot3d(structure, spacefill=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'matsciml' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/mila/d/daniel.levy/envs/matsciml/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "symmops = list(SpaceGroup(sg_symbol_from_int_number(spacegroup)).symmetry_ops)\n",
    "symmops_real = spga.get_symmetry_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd38b9d883354679ba261332eed73c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def apply_symmop(symmop, structure, frac_coords=None):\n",
    "    if frac_coords is None:\n",
    "        frac_coords = structure.frac_coords\n",
    "    new_frac_coords = symmop.operate_multi(frac_coords) % 1\n",
    "    return Structure(structure.lattice, structure.species, new_frac_coords)\n",
    "\n",
    "plot3d(apply_symmop(symmops[3], structure), spacefill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffcsp.common.utils import SinkhornDistance\n",
    "import torch\n",
    "sinkhorn = SinkhornDistance(eps = 0.1, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_symmop_torch(affine_matrix, frac_coords):\n",
    "    ones_vec = torch.ones(structure.frac_coords.shape[0], 1, device=frac_coords.device)\n",
    "    affine_points = torch.cat([frac_coords, ones_vec], 1)\n",
    "    return torch.inner(affine_matrix, affine_points)[:-1].T%1\n",
    "\n",
    "\n",
    "def apply_symmop(symmop, structure, frac_coords=None):\n",
    "    if frac_coords is None:\n",
    "        frac_coords = structure.frac_coords\n",
    "    new_frac_coords = symmop.operate_multi(frac_coords) % 1\n",
    "    return Structure(structure.lattice, structure.species, new_frac_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9200089  0.38620993 0.26396334]\n",
      " [0.2531947  0.05177674 0.76721644]\n",
      " [0.92101866 0.3859573  0.64865893]\n",
      " [0.5892098  0.7189829  0.01634433]\n",
      " [0.25398096 0.05229295 0.38554794]]\n"
     ]
    }
   ],
   "source": [
    "frac_coords = structure.frac_coords\n",
    "print(frac_coords)\n",
    "frac_coords_torch = torch.Tensor(frac_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use symmetry to loss to symmetrize crystal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "gradient_factor = 0.1\n",
    "\n",
    "gradients = []\n",
    "losses = []\n",
    "x = frac_coords_torch.clone()\n",
    "x_syms = [x]\n",
    "symmops_torch = [torch.Tensor(symmop.affine_matrix, device=x.device) for symmop in symmops]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 60.75it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(10)):\n",
    "    x.requires_grad=True\n",
    "    loss = torch.zeros(1, requires_grad=True)\n",
    "    loss_list = []\n",
    "\n",
    "    for symmop_i in range(len(symmops)):\n",
    "        x_sym = apply_symmop_torch(symmops_torch[symmop_i], x)\n",
    "        dist, P, C = sinkhorn(x, x_sym)\n",
    "        loss_i = dist\n",
    "        loss = loss + (1/2)*loss_i\n",
    "        loss_list.append(loss_i)\n",
    "\n",
    "    gradient = grad(loss, x, allow_unused=False)\n",
    "    x = (x - gradient_factor*gradient[0]).detach() % 1\n",
    "    gradients.append(gradient[0].detach())\n",
    "    x_syms.append(x.detach())\n",
    "    losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Formula (Ca1 Mg2 As2)\n",
      "Reduced Formula: Ca(MgAs)2\n",
      "abc   :   6.759699   5.424852   7.598948\n",
      "angles:  90.000000  90.000000 153.670496\n",
      "pbc   :       True       True       True\n",
      "Sites (5)\n",
      "  #  SP           a         b    c\n",
      "---  ----  --------  --------  ---\n",
      "  0  As    0.010886  0.48845     0\n",
      "  1  As    0.488468  0.007997    1\n",
      "  2  Mg    0.992003  0.511532    1\n",
      "  3  Ca    0.503169  0.496831    0\n",
      "  4  Mg    0.51155   0.989114    0\n"
     ]
    }
   ],
   "source": [
    "sym_structure = Structure(structure.lattice, structure.species, x_syms[-1])\n",
    "print(sym_structure)\n",
    "print(\"spacegroup: \", SpacegroupAnalyzer(sym_structure, symprec=0.1).get_space_group_number())\n",
    "plot3d(sym_structure, spacefill=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matsciml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
